{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa96779a-6a55-47c4-9f4c-2a3351b7ec3f",
   "metadata": {},
   "source": [
    "\n",
    "1. Data Ingestion Pipeline:\n",
    "   a. Design a data ingestion pipeline that collects and stores data from various sources such as databases, APIs, and streaming platforms.\n",
    "   b. Implement a real-time data ingestion pipeline for processing sensor data from IoT devices.\n",
    "   c. Develop a data ingestion pipeline that handles data from different file formats (CSV, JSON, etc.) and performs data validation and cleansing.\n",
    "\n",
    "\n",
    "Ans :a. Designing a Data Ingestion Pipeline:\n",
    "To design a data ingestion pipeline that collects and stores data from various sources, you can follow these general steps:\n",
    "\n",
    "1. Identify data sources: Determine the different sources from which you need to collect data, such as databases, APIs, streaming platforms, or any other relevant sources.\n",
    "\n",
    "2. Understand data formats: Analyze the data formats used by each source, such as structured (relational databases), semi-structured (JSON), or unstructured (log files), to determine the appropriate approach for extracting and processing the data.\n",
    "\n",
    "3. Define extraction methods: Based on the data sources and formats, choose the appropriate methods for extracting data. For databases, you can use SQL queries or database connectors. For APIs, you might need to make HTTP requests and handle authentication. Streaming platforms may require specialized connectors or libraries.\n",
    "\n",
    "4. Data transformation and validation: Once the data is extracted, perform any necessary data transformation and validation tasks. This may include converting data formats, cleaning and standardizing data, and performing quality checks to ensure data integrity.\n",
    "\n",
    "5. Store the data: Determine the storage solution based on your requirements. It can be a relational database, a distributed storage system like Hadoop or Apache Kafka, a cloud-based storage service like Amazon S3 or Google Cloud Storage, or any other suitable storage option.\n",
    "\n",
    "6. Schedule and automate: Set up a schedule or trigger mechanism to run the data ingestion pipeline at specified intervals or in real-time. Automate the process to ensure continuous data collection and storage.\n",
    "\n",
    "7. Monitoring and error handling: Implement monitoring mechanisms to track the health and performance of the pipeline. Include error handling and logging to handle any failures or issues that may arise during data ingestion.\n",
    "\n",
    "b. Implementing a Real-Time Data Ingestion Pipeline for IoT Sensor Data:\n",
    "To implement a real-time data ingestion pipeline for processing sensor data from IoT devices, you can use the following technologies and steps:\n",
    "\n",
    "1. IoT Device Integration: Establish a connection and integration with the IoT devices. This may involve using device-specific protocols, such as MQTT or CoAP, to receive data from the sensors.\n",
    "\n",
    "2. Message Queue: Set up a message queue system like Apache Kafka or RabbitMQ to handle the real-time data stream from the IoT devices. The message queue acts as a buffer, allowing you to process data asynchronously and handle high data volumes.\n",
    "\n",
    "3. Data Processing: Implement data processing logic to parse, transform, and analyze the sensor data. This can involve extracting relevant information, aggregating data, applying business rules, or performing any other required data manipulations.\n",
    "\n",
    "4. Real-Time Analytics: Integrate real-time analytics frameworks like Apache Flink, Apache Spark Streaming, or AWS Kinesis Data Analytics to perform complex computations and derive insights from the streaming sensor data.\n",
    "\n",
    "5. Storage and Persistence: Store the processed sensor data in a suitable data storage solution. Depending on the use case, you can choose options such as time-series databases like InfluxDB, columnar databases like Apache Cassandra, or cloud-based storage services like AWS S3 or Azure Blob Storage.\n",
    "\n",
    "6. Visualization and Alerting: Implement a visualization layer to display the processed data in real-time dashboards or reports. Set up alerting mechanisms to notify stakeholders of any anomalies or predefined conditions that require attention.\n",
    "\n",
    "7. Scalability and Fault-Tolerance: Design the pipeline to be scalable and fault-tolerant to handle high data volumes and ensure continuous operation. This can involve using distributed systems, containerization technologies like Docker or Kubernetes, and implementing redundancy and monitoring mechanisms.\n",
    "\n",
    "c. Developing a Data Ingestion Pipeline for Handling Different File Formats:\n",
    "\n",
    "To develop a data ingestion pipeline that handles data from different file formats (such as CSV, JSON, etc.) and performs data validation and cleansing, you can follow these steps:\n",
    "\n",
    "1. Identify input sources: Determine the sources from which you will be ingesting data. These sources can include local files, remote file servers, or cloud storage services.\n",
    "\n",
    "2. File format detection: Implement a mechanism to detect the file format automatically. This can be based on file extensions or by analyzing the file content to determine its structure.\n",
    "\n",
    "3. File ingestion: Develop code or use existing libraries to read and ingest data from various file formats such as CSV, JSON, XML, or any other formats you need to support.\n",
    "\n",
    "4. Data validation: Apply data validation rules to ensure the integrity and quality of the ingested data. Validate data types, check for missing or inconsistent values, and apply any specific validation rules based on the business requirements.\n",
    "\n",
    "5. Data cleansing: Perform data cleansing operations to address any inconsistencies, errors, or outliers in the ingested data. This may involve removing duplicate records, handling missing values, standardizing formats, or performing any necessary data transformations.\n",
    "\n",
    "6. Data transformation: Apply any required data transformations to prepare the ingested data for further processing or storage. This can include aggregating data, splitting fields, merging datasets, or applying business-specific transformations.\n",
    "\n",
    "7. Store the data: Choose an appropriate storage solution based on your requirements. It can be a relational database, a NoSQL database, a distributed file system, or a cloud-based storage service.\n",
    "\n",
    "8. Automation and scheduling: Implement automation and scheduling mechanisms to run the data ingestion pipeline at regular intervals or trigger it based on specific events or conditions.\n",
    "\n",
    "9. Error handling and logging: Implement error handling mechanisms to handle any exceptions or failures that may occur during the data ingestion process. Set up logging to capture relevant information for troubleshooting and monitoring purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c9fb2-2c1e-4284-8f01-0a0de9a09641",
   "metadata": {},
   "source": [
    "2. Model Training:\n",
    "   a. Build a machine learning model to predict customer churn based on a given dataset. Train the model using appropriate algorithms and evaluate its performance.\n",
    "   b. Develop a model training pipeline that incorporates feature engineering techniques such as one-hot encoding, feature scaling, and dimensionality reduction.\n",
    "   c. Train a deep learning model for image classification using transfer learning and fine-tuning techniques.\n",
    "\n",
    "\n",
    "Ans :a. Building a Machine Learning Model for Customer Churn Prediction:\n",
    "To build a machine learning model for customer churn prediction, follow these steps:\n",
    "\n",
    "1. Data Understanding: Start by understanding the dataset that contains information about customers, their characteristics, and whether they churned or not. Analyze the features and their relationships with the target variable (churn).\n",
    "\n",
    "2. Data Preprocessing: Preprocess the dataset by handling missing values, outliers, and any data inconsistencies. Convert categorical variables to numerical representations, if needed.\n",
    "\n",
    "3. Feature Selection/Engineering: Select relevant features that are likely to impact customer churn. Perform feature engineering techniques like creating new features, combining or transforming existing ones, or applying domain-specific knowledge to enhance the predictive power of the model.\n",
    "\n",
    "4. Data Split: Split the dataset into training and testing sets. The training set will be used to train the model, and the testing set will be used to evaluate its performance.\n",
    "\n",
    "5. Model Selection: Choose an appropriate machine learning algorithm for customer churn prediction. Common algorithms include logistic regression, decision trees, random forests, gradient boosting, or support vector machines (SVM). Consider the characteristics of your dataset and the interpretability versus complexity trade-off.\n",
    "\n",
    "6. Model Training: Train the selected model using the training set. Fit the model to the data and tune its hyperparameters to optimize its performance.\n",
    "\n",
    "7. Model Evaluation: Evaluate the trained model using the testing set. Calculate relevant evaluation metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) to assess its predictive performance.\n",
    "\n",
    "8. Model Optimization: Fine-tune the model by iterating on steps 5 to 7. Experiment with different algorithms, feature engineering techniques, and hyperparameter configurations to improve the model's performance.\n",
    "\n",
    "9. Model Deployment: Once satisfied with the model's performance, deploy it in a production environment to make predictions on new customer data. Monitor the model's performance over time and retrain/update it as needed.\n",
    "\n",
    "b. Developing a Model Training Pipeline with Feature Engineering Techniques:\n",
    "To develop a model training pipeline that incorporates feature engineering techniques such as one-hot encoding, feature scaling, and dimensionality reduction, follow these steps:\n",
    "\n",
    "1. Data Preprocessing: Start by preprocessing the raw dataset. Handle missing values, outliers, and data inconsistencies. Split the dataset into features (X) and the target variable (y).\n",
    "\n",
    "2. Feature Engineering: Apply feature engineering techniques such as one-hot encoding to convert categorical variables into binary features. Use techniques like feature scaling (e.g., normalization or standardization) to bring numerical features to a similar scale. Consider applying dimensionality reduction techniques like principal component analysis (PCA) or feature selection methods to reduce the dimensionality of the feature space.\n",
    "\n",
    "3. Data Split: Split the preprocessed dataset into training and testing sets. This ensures that feature engineering techniques are applied separately to the training and testing data, preventing information leakage.\n",
    "\n",
    "4. Model Training: Choose an appropriate machine learning algorithm for the task at hand. Train the model using the training set, which now contains the engineered features. Tune the hyperparameters of the model to optimize its performance.\n",
    "\n",
    "5. Model Evaluation: Evaluate the trained model using the testing set. Calculate relevant evaluation metrics to assess its performance. Compare the performance with and without the inclusion of feature engineering techniques to determine their impact.\n",
    "\n",
    "6. Model Optimization: Iterate on steps 2 to 5, experimenting with different feature engineering techniques, algorithms, and hyperparameter configurations. Fine-tune the model to achieve the best possible performance.\n",
    "\n",
    "c. Training a Deep Learning Model for Image Classification using Transfer Learning and Fine-tuning Techniques:\n",
    "To train a deep learning model for image classification using transfer learning and fine-tuning techniques, follow these steps:\n",
    "\n",
    "1. Dataset Preparation: Gather a labeled dataset of images for training and testing. Ensure the dataset is diverse and representative of the classes you want to classify.\n",
    "\n",
    "2. Transfer Learning: Choose a pre-trained deep learning model, such as VGG, ResNet, Inception, or MobileNet, that has been trained on a large-scale image dataset (e.g., ImageNet). Load the pre-trained model without the classification head.\n",
    "\n",
    "3. Model Architecture: Create a new classification head or fully connected layers that will be appended to the pre-trained model. The classification head should consist of layers that map the features extracted by the pre-trained model to the number of classes in your specific image classification task.\n",
    "\n",
    "4. Data Augmentation: Apply data augmentation techniques such as random rotations, flips, zooms, or crops to artificially increase the diversity and size of the training dataset. This helps the model generalize better to new, unseen images.\n",
    "\n",
    "5. Fine-tuning: Freeze the pre-trained layers of the model to prevent their weights from being updated during initial training. Train the classification head using the labeled images from your dataset. Gradually unfreeze some of the pre-trained layers and continue training to fine-tune the model on your specific task. This allows the model to adapt to the specific features relevant to your image classification problem.\n",
    "\n",
    "6. Model Training: Train the model using the labeled images, augmented dataset, and the fine-tuning strategy described above. Use an appropriate optimizer (e.g., Adam, RMSprop) and loss function (e.g., categorical cross-entropy) for the classification task. Monitor the model's performance on a validation set during training.\n",
    "\n",
    "7. Model Evaluation: Evaluate the trained model on a separate testing set to assess its performance. Calculate relevant evaluation metrics such as accuracy, precision, recall, and F1-score to measure its classification performance.\n",
    "\n",
    "8. Hyperparameter Tuning: Experiment with different hyperparameter configurations, such as learning rate, batch size, or regularization techniques, to improve the model's performance. Use techniques like grid search or random search to find the optimal combination of hyperparameters.\n",
    "\n",
    "9. Model Deployment: Once satisfied with the model's performance, save the trained model weights and deploy it in a production environment. Make predictions on new, unseen images and monitor the model's performance over time. Retrain or update the model as needed to maintain its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703f6dd-f5be-40be-82b0-d51968515160",
   "metadata": {},
   "source": [
    "3. Model Validation:\n",
    "   a. Implement cross-validation to evaluate the performance of a regression model for predicting housing prices.\n",
    "   b. Perform model validation using different evaluation metrics such as accuracy, precision, recall, and F1 score for a binary classification problem.\n",
    "   c. Design a model validation strategy that incorporates stratified sampling to handle imbalanced datasets.\n",
    "\n",
    "\n",
    "Ans :a. Implementing Cross-Validation for Evaluating a Regression Model:\n",
    "Cross-validation is a technique used to assess the performance of a machine learning model. Here's how you can implement cross-validation for evaluating the performance of a regression model for predicting housing prices:\n",
    "\n",
    "1. Dataset Split: Split the dataset into a training set and a testing set. Typically, a percentage like 80% for training and 20% for testing is used, but you can adjust this ratio based on your specific needs.\n",
    "\n",
    "2. Cross-Validation Folds: Divide the training set into k equally sized folds. The value of k depends on your preference, but commonly used values are 5 or 10.\n",
    "\n",
    "3. Model Training and Evaluation: Iterate over each fold as a validation set while using the remaining k-1 folds as the training set. Train the regression model on the training set and evaluate its performance on the validation set using an appropriate evaluation metric for regression tasks, such as mean squared error (MSE), root mean squared error (RMSE), or mean absolute error (MAE).\n",
    "\n",
    "4. Performance Metrics: Calculate the performance metric (e.g., average MSE, RMSE, or MAE) for each fold. Optionally, calculate additional metrics like R-squared or adjusted R-squared to evaluate the model's goodness of fit.\n",
    "\n",
    "5. Overall Performance: Calculate the average and standard deviation of the performance metrics across all the folds. This provides an estimate of the model's performance and its variability.\n",
    "\n",
    "b. Performing Model Validation with Different Evaluation Metrics for Binary Classification:\n",
    "Model validation for binary classification involves assessing the performance of a classification model. Here's how you can perform model validation using different evaluation metrics:\n",
    "\n",
    "1. Dataset Split: Split the dataset into a training set and a testing set, using the same ratio as mentioned earlier (e.g., 80% for training, 20% for testing).\n",
    "\n",
    "2. Model Training: Train the binary classification model on the training set using an appropriate algorithm such as logistic regression, decision trees, random forests, support vector machines, or neural networks.\n",
    "\n",
    "3. Model Evaluation: Evaluate the trained model on the testing set. Calculate the following evaluation metrics:\n",
    "\n",
    "   - Accuracy: The proportion of correct predictions over the total number of predictions.\n",
    "\n",
    "   - Precision: The proportion of true positive predictions over the total number of positive predictions. Precision measures how well the model identifies positive cases correctly.\n",
    "\n",
    "   - Recall: The proportion of true positive predictions over the total number of actual positive cases. Recall measures how well the model captures all positive cases.\n",
    "\n",
    "   - F1 Score: The harmonic mean of precision and recall. It provides a balanced measure of the model's accuracy, considering both precision and recall.\n",
    "\n",
    "   Additionally, you can calculate other metrics like the area under the receiver operating characteristic curve (AUC-ROC) or the area under the precision-recall curve (AUC-PR) for a more comprehensive evaluation.\n",
    "\n",
    "4. Interpretation: Interpret the evaluation metrics to assess the model's performance. Consider the specific requirements and objectives of your classification problem to determine which metrics are most important in your context.\n",
    "\n",
    "c. Designing a Model Validation Strategy with Stratified Sampling for Imbalanced Datasets:\n",
    "When dealing with imbalanced datasets where the distribution of classes is highly skewed, it is important to use stratified sampling during model validation to ensure representative evaluation. Here's how you can design a model validation strategy incorporating stratified sampling:\n",
    "\n",
    "1. Dataset Split: Split the imbalanced dataset into a training set and a testing set, using the same ratio as mentioned earlier (e.g., 80% for training, 20% for testing).\n",
    "\n",
    "2. Stratified Sampling: Ensure that the splitting process maintains the class distribution proportion in both the training and testing sets. Stratified sampling ensures that each class is represented in the training and testing sets in a manner that reflects the original dataset's class distribution.\n",
    "\n",
    "3. Model Training: Train the classification model on the training set using appropriate algorithms and techniques suitable for handling imbalanced datasets, such as oversampling techniques (e.g., SMOTE), undersampling techniques (e.g., random undersampling), or ensemble methods (e.g., XGBoost, AdaBoost).\n",
    "\n",
    "4. Model Evaluation: Evaluate the trained model on the stratified testing set. Calculate the evaluation metrics, including accuracy, precision, recall, F1 score, AUC-ROC, or AUC-PR, as mentioned earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368fc15d-3f00-45e9-b724-9249003b2e6f",
   "metadata": {},
   "source": [
    "4. Deployment Strategy:\n",
    "   a. Create a deployment strategy for a machine learning model that provides real-time recommendations based on user interactions.\n",
    "   b. Develop a deployment pipeline that automates the process of deploying machine learning models to cloud platforms such as AWS or Azure.\n",
    "   c. Design a monitoring and maintenance strategy for deployed models to ensure their performance and reliability over time.\n",
    "\n",
    "\n",
    "Ans :a. Creating a Deployment Strategy for a Real-Time Recommendation ML Model:\n",
    "When creating a deployment strategy for a machine learning model that provides real-time recommendations based on user interactions, consider the following steps:\n",
    "\n",
    "1. Model Packaging: Package the trained ML model into a format suitable for deployment, such as a serialized file or container image.\n",
    "\n",
    "2. Real-Time Data Ingestion: Set up a data ingestion pipeline to capture user interactions and send them to the deployed model in real-time. This can involve integrating with event streaming platforms like Apache Kafka or using APIs to receive user interactions.\n",
    "\n",
    "3. Model Deployment: Deploy the packaged ML model in an environment that supports real-time inference, such as a server or cloud-based platform. This can be done using technologies like Flask, FastAPI, Docker, or serverless platforms like AWS Lambda or Azure Functions.\n",
    "\n",
    "4. Scaling and Load Balancing: Configure the deployment environment to handle increased load and scalability requirements. Use load balancers or auto-scaling mechanisms to ensure the model can handle concurrent requests and provide recommendations efficiently.\n",
    "\n",
    "5. Real-Time Recommendation Engine: Develop a recommendation engine that takes user interactions as input, passes them through the deployed model for inference, and returns real-time recommendations based on the model's predictions. This can involve using caching mechanisms, personalization techniques, or ranking algorithms to optimize the recommendation process.\n",
    "\n",
    "6. Integration with User Interfaces: Integrate the real-time recommendation engine with the user interfaces where recommendations will be displayed. This can be done via APIs, SDKs, or libraries that communicate with the recommendation engine to fetch and display recommendations to users in real-time.\n",
    "\n",
    "7. Monitoring and Analytics: Implement monitoring mechanisms to track the performance and reliability of the deployed model and recommendation engine. Collect metrics such as response time, throughput, error rates, and user feedback to assess the system's health and make improvements as needed.\n",
    "\n",
    "8. Feedback Loop and Model Updates: Incorporate a feedback loop to continuously collect user feedback and interactions. Use this feedback to improve the model's performance and relevance over time. Implement mechanisms to periodically update the model with new data, retrain it, and deploy updated versions to ensure the recommendations stay up-to-date and accurate.\n",
    "\n",
    "b. Developing a Deployment Pipeline for Machine Learning Models on Cloud Platforms:\n",
    "To automate the process of deploying machine learning models to cloud platforms such as AWS or Azure, you can follow these steps:\n",
    "\n",
    "1. Model Packaging: Package the trained ML model into a suitable format for deployment, such as a serialized file or container image.\n",
    "\n",
    "2. Infrastructure as Code: Use infrastructure as code (IaC) tools like AWS CloudFormation, Azure Resource Manager, or Terraform to define and provision the necessary cloud resources for the deployment pipeline, including virtual machines, containers, storage, networking, and security configurations.\n",
    "\n",
    "3. Continuous Integration and Continuous Deployment (CI/CD): Set up a CI/CD pipeline using tools like Jenkins, GitLab CI/CD, or AWS CodePipeline to automate the build, testing, and deployment process. Configure the pipeline to trigger whenever there are changes to the model code or data.\n",
    "\n",
    "4. Model Versioning and Artifact Storage: Use version control systems (e.g., Git) to manage the code and configuration files of the ML model. Store the model artifacts, such as serialized files or container images, in a versioned artifact repository like AWS S3 or Azure Container Registry.\n",
    "\n",
    "5. Automated Testing: Implement automated tests to validate the model's behavior and performance during the deployment pipeline. This can include unit tests, integration tests, and performance tests to ensure the model meets the desired quality criteria.\n",
    "\n",
    "6. Deployment Configuration: Define deployment configurations that specify the target cloud platform, deployment environment, resource requirements, and dependencies for the ML model. These configurations can be stored in configuration files or managed through environment variables.\n",
    "\n",
    "7. Infrastructure Provisioning and Deployment: Configure the CI/CD pipeline to provision the necessary infrastructure resources on the cloud platform and deploy the model using the defined deployment configurations. This can involve using cloud-specific deployment tools, containerization technologies (e.g., Docker), or serverless platforms.\n",
    "\n",
    "8. Deployment Verification and Monitoring: After the deployment, implement verification steps to ensure the model is functioning as expected. Monitor the deployed model's performance, logging, and error handling to detect and address any issues or anomalies that may arise during runtime.\n",
    "\n",
    "c. Designing a Monitoring and Maintenance Strategy for Deployed Models:\n",
    "To ensure the performance and reliability of deployed machine learning models over time, design a monitoring and maintenance strategy that includes the following steps:\n",
    "\n",
    "1. Monitoring Metrics: Define key performance indicators (KPIs) and metrics to monitor the model's performance, such as response time, accuracy, throughput, error rates, and resource utilization. Set up monitoring systems like AWS CloudWatch, Azure Monitor, or Prometheus to collect and track these metrics.\n",
    "\n",
    "2. Alerting and Notifications: Configure alerting mechanisms to notify the relevant stakeholders when the model's performance or health deviates from acceptable thresholds. Use tools like PagerDuty, Slack, or email notifications to ensure timely awareness and response to critical issues.\n",
    "\n",
    "3. Logs and Error Handling: Implement logging mechanisms to capture important events, errors, and exceptions that occur during model inference. Log relevant information for troubleshooting purposes, including input data, predictions, and any errors encountered. Implement appropriate error handling strategies to handle exceptions gracefully and provide meaningful error messages.\n",
    "\n",
    "4. Model Drift Detection: Continuously monitor the data distribution and patterns in the input data to detect concept drift or data drift. Implement statistical tests, drift detection algorithms, or use specialized tools like TensorFlow Data Validation (TFDV) or KubeFlow Fairing to detect and quantify drift.\n",
    "\n",
    "5. Retraining and Model Updates: Establish a process for periodically retraining the model using new data or when significant model drift is detected. Define criteria and triggers for model updates, such as a drop in performance or changes in the business environment. Automate the retraining and deployment pipeline to facilitate seamless model updates.\n",
    "\n",
    "6. Data Quality Monitoring: Monitor the quality and integrity of the input data used for model inference. Implement checks for missing values, outliers, or data inconsistencies. Use data validation techniques and data quality monitoring tools to ensure the reliability and accuracy of the input data.\n",
    "\n",
    "7. Model Governance and Compliance: Ensure compliance with regulatory and privacy requirements when collecting, storing, and processing user data. Implement appropriate access controls, encryption, and anonymization techniques to protect user privacy and sensitive information. Establish a governance framework to track and manage model versions, changes, and associated documentation.\n",
    "\n",
    "8. Feedback and Iteration: Establish mechanisms to collect user feedback, customer satisfaction, or other relevant metrics to assess the model's performance and user experience. Incorporate this feedback into the model improvement cycle to continuously enhance the model's performance and relevance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e97a8-1083-4f51-beb3-d98b9c55ab72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

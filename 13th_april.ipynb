{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a34907-5fcd-49a6-8628-f7ed3a7065e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "'''\n",
    "Random Forest Regressor is an ensemble learning technique based on the Random Forest algorithm, used for regression tasks. It is built upon the idea\n",
    "of constructing multiple decision trees during training and averaging their predictions to improve accuracy and robustness in predicting continuous \n",
    "numerical values.\n",
    "'''\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "'''\n",
    "Random Forest Regressor reduces overfitting through two primary mechanisms:\n",
    "\n",
    "Bootstrap Aggregating (Bagging): It creates multiple decision trees on different subsets of the training data through bootstrapping, thus exposing \n",
    "each tree to different perspectives of the dataset. The aggregation of predictions from these diverse trees helps reduce variance and overfitting.\n",
    "Feature Randomization: Each split in a decision tree within the Random Forest considers only a subset of features randomly selected from the total\n",
    "feature set. This randomness reduces the correlation between individual trees and improves the model's generalization by preventing overfitting.\n",
    "'''\n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "'''\n",
    "Random Forest Regressor aggregates predictions by taking the average (or sometimes the median) of predictions from all individual decision trees in \n",
    "the forest. For regression tasks, the final output of the Random Forest Regressor is the average prediction made by the constituent decision trees.\n",
    "'''\n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "'''\n",
    "Some key hyperparameters of the Random Forest Regressor include:\n",
    "\n",
    "n_estimators: The number of trees in the forest.\n",
    "max_depth: The maximum depth allowed for each decision tree.\n",
    "min_samples_split: The minimum number of samples required to split an internal node.\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "max_features: The number of features to consider when looking for the best split.\n",
    "'''\n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "'''\n",
    "Random Forest Regressor: It uses an ensemble of multiple decision trees. It mitigates overfitting by combining predictions from diverse trees and\n",
    "feature randomization.\n",
    "Decision Tree Regressor: It's a single decision tree that recursively splits the dataset based on features to make predictions. It is prone to \n",
    "overfitting, especially when the tree grows deep.\n",
    "'''\n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "'''\n",
    "Advantages:\n",
    "\n",
    "Generally robust against overfitting due to ensemble learning.\n",
    "Handles large datasets with high dimensionality well.\n",
    "Requires minimal data preprocessing.\n",
    "Provides feature importance ranking.\n",
    "Disadvantages:\n",
    "\n",
    "Can be computationally expensive, especially with a large number of trees and features.\n",
    "Interpretability might be reduced when using a large number of trees.\n",
    "May not perform as well when extrapolating beyond the range of the training data.\n",
    "'''\n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "'''\n",
    "The output of the Random Forest Regressor is a continuous numerical value representing the prediction for the target variable. For each input sample,\n",
    "the Random Forest Regressor predicts a continuous output based on the aggregated predictions of all the trees in the forest.\n",
    "'''\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "'''\n",
    "Yes, Random Forest can be used for both regression and classification tasks. For classification tasks, it employs the same ensemble approach, but the\n",
    "output is a class label or class probabilities instead of a continuous value as in regression tasks.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

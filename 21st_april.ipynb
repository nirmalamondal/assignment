{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe6ecf-81ea-49b3-9b7d-67eabf8aeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the\n",
    "performance of a KNN classifier or regressor?\n",
    "'''\n",
    "Euclidean distance: Measures the shortest straight-line distance between two points in the feature space.\n",
    "Manhattan distance: Measures the distance as the sum of the absolute differences between the coordinates of the two points along each dimension.\n",
    "\n",
    "The main difference lies in how distance is calculated between points in different dimensions. Euclidean distance considers the square of the \n",
    "differences, while Manhattan distance considers the absolute differences. Euclidean distance is sensitive to magnitudes, emphasizing large differences\n",
    "more. Manhattan distance is less sensitive to outliers and emphasizes differences along each dimension equally.\n",
    "The choice of distance metric can significantly affect KNN performance. Euclidean distance might be suitable when all features are equally important \n",
    "and differences in magnitudes matter. Manhattan distance could be preferable when features have different scales or when outliers are present.\n",
    "'''\n",
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?\n",
    "'''\n",
    "Cross-validation: Evaluate performance using different K values and select the one with the best performance on validation data.\n",
    "Grid search: Test various K values over a defined range and choose the one with the best performance.\n",
    "Elbow method: Plot accuracy (or other performance metric) against K values and choose the value where performance starts to plateau.\n",
    "'''\n",
    "\n",
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? Inwhat situations might you choose one distance metric over the other?\n",
    "'''\n",
    "Euclidean distance works well when features are on the same scale and differences in magnitudes are significant.\n",
    "Manhattan distance might perform better when features have different scales or when outliers can influence distance measures, as it is less affected\n",
    "by outliers.\n",
    "'''\n",
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?\n",
    "'''\n",
    "Common hyperparameters in KNN include:\n",
    "\n",
    "K: Number of neighbors.\n",
    "Distance metric: Euclidean, Manhattan, etc.\n",
    "These hyperparameters significantly impact model performance. Tuning K helps balance between bias and variance, while choosing an appropriate \n",
    "distance metric affects how the model measures similarity between points. Grid search, cross-validation, or systematic testing over a range of values \n",
    "can help find the best combination of hyperparameters.\n",
    "'''\n",
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?\n",
    "'''\n",
    "A larger training set generally leads to a better representation of the underlying patterns in the data, reducing variance and improving \n",
    "generalization.However, an excessively large training set can also increase computational complexity and training time in KNN.\n",
    "\n",
    "Techniques to optimize the training set size include:\n",
    "Using techniques like cross-validation to assess model performance with varying training set sizes.\n",
    "Utilizing techniques like learning curves to visualize how model performance changes with different training set sizes.\n",
    "'''\n",
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?\n",
    "'''\n",
    "Drawbacks of KNN include:\n",
    "High computational cost, especially with large datasets.\n",
    "Sensitivity to irrelevant and noisy features.\n",
    "The need for proper scaling and handling of missing data.\n",
    "\n",
    "To improve performance:\n",
    "Feature selection/engineering to reduce irrelevant features.\n",
    "Dimensionality reduction techniques like PCA to reduce computational load.\n",
    "Proper data preprocessing, scaling, and handling of missing values to enhance the quality of input data.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
